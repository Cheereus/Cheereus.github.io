---
layout:     post
title:      支持向量机
subtitle:   《统计学习方法》笔记 第7章
date:       2020-01-28
author:     Cheereus
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Machine Learning
    - 统计学习方法
---

## 第7章 支持向量机

### 7.1 线性可分支持向量机与硬间隔最大化

#### 7.1.1 线性可分支持向量机

给定线性可分训练数据集，通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为

$$\omega^* \cdot x + b^*=0$$

以及相应的分类决策函数

$$f(x)=\text{sign}(\omega^* \cdot x + b^*)$$

称为线性可分支持向量机。

#### 7.1.2 函数间隔和几何间隔

函数间隔：

对于给定的数据集 $T$ 和超平面 $(\omega,b)$，定义超平面 $(\omega,b)$ 关于样本点 $(x_i,y_i)$ 的函数间隔为

$$\hat{\gamma_i}=y_i(\omega\cdot x+b)$$

定义超平面 $(\omega,b)$ 关于训练数据集 $T$ 的函数间隔为超平面 $(\omega,b)$ 关于 $T$ 中所有样本点 $(x_i,y_i)$ 的函数间隔之最小值，即

$$\hat{\gamma}=\underset{i=1,\cdots,N}{\min}\hat{\gamma_i}$$

几何间隔：

对于给定的训练数据集 $T$ 和超平面 $(\omega,b)$，定义超平面 $(\omega,b)$ 关于样本点 $(x_i,y_i)$ 的几何间隔为

$$\gamma_i=y_i\bigg(\frac{\omega}{\lVert\omega\rVert}\cdot x_i +\frac{b}{\lVert\omega\rVert}\bigg)$$

定义超平面 $(\omega,b)$ 关于训练数据集 $T$ 的几何间隔为超平面 $(\omega,b)$ 关于 $T$ 中所有样本点 $(\omega,b)$ 的几何间隔之最小值，即

$$\gamma=\underset{i=1,\cdots,N}{\min}\gamma_i$$

由上述定义可知，函数间隔和几何间隔有下面的关系：

$$\gamma_i=\frac{\hat\gamma_i}{\lVert\omega\rVert}$$

$$\gamma=\frac{\hat\gamma}{\lVert\omega\rVert}$$

#### 7.1.3 间隔最大化

##### 1. 最大间隔分离超平面

输入：线性可分的数据集 $T=\\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\\}$，其中 $x_i \in \mathcal{R}^n,y \in \\{+1,-1\\},i=1,2,\cdots,N$；

输出：最大间隔分离超平面和分类决策函数。

(1) 构造并求解约束最优化问题：

$$\underset{\omega,b}{\min}\frac{1}{2}\lVert\omega\rVert^2$$

$$s.t.\ \ y_i(\omega\cdot x_i+b)-1 \geq 0,\ \ i=1,2,\cdots,N$$

求得最优解 $\omega^*,b^*$。

(2) 由此得到分离超平面：

$$\omega^*\cdot x+b^*=0$$

分类决策函数：

$$f(x)=\text{sign}(\omega^*\cdot x+b^*)$$

##### 2. 最大间隔分离超平面的存在唯一性

若训练数据集 $T$ 线性可分，则可将训练数据集中的样本点完全正确分开的最大间隔分离超平面存在且唯一。

##### 3. 支持向量和间隔边界

在线性可分情况下，训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量(support vector)。支持向量是使约束条件式等号成立的点，即

$$y_i(\omega\cdot x_i+b)-1=0$$

对 $y_i=+1$ 的正例点，支持向量在超平面

$$H_1:\omega\cdot x+b=1$$

上。对 $y_i=-1$ 的正例点，支持向量在超平面

$$H_2:\omega\cdot x+b=-1$$

上。在 $H_1$ 和 $H_2$ 上的点就是支持向量。
