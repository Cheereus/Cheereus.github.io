---
layout:     post
title:      统计学习及监督学习概述
subtitle:   《统计学习方法》笔记 第1章
date:       2020-01-15
author:     Cheereus
header-img: img/post-bg-ml.jpg
catalog: true
tags:
    - Machine Learning
    - 统计学习方法
---

## 第1章 统计学习及监督学习概论

### 1.1 统计学习

1. 统计学习的特点

    统计学习(statistical learning)是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科，也称为为统计机器学习(statistical machine learning)。

    统计学习的主要特点是：

    (1) 统计学习以计算机及网络为平台，是建立在计算机及网络上的；

    (2) 统计学习以数据为研究对象，是数据驱动的学科；

    (3) 统计学习的目的是对数据进行预测与分析；

    (4) 统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析；

    (5) 统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论。

2. 统计学习的对象

    统计学习研究的对象是数据(data)。它从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。

    统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。由于数据具有统计规律性，所以可以用概率统计方法处理它们。

3. 统计学习的目的

    统计学习用于对数据的预测和分析，特别是对未知新数据的预测与分析。对数据的预测与分析是通过构建概率统计模型实现的。统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。

4. 统计学习的方法

    统计学习的方法是基于数据构建概率统计模型从而对数据进行预测与分析。统计学习由监督学习(supervised learning)、无监督学习(unsupervised learning)和强化学习(reinforcement learning)等组成。

    统计学习方法可以概括如下：

    从给定的、有限的、用于学习的训练数据(training data)集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间(hypothesis space)；

    应用某个评价准则(evaluation criterion)，从假设空间中选取一个最优模型，使它对已知的训练数据及未知的测试数据(test data)在给定的评价准则下有最优的预测；

    最优模型的选取由算法实现。

    这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法。称其为统计学习方法的三要素，简称为：

    模型(model)、策略(strategy)和算法(algorithm)。

    实现统计学习方法的步骤如下：

    (1) 得到一个有限的训练数据集合；

    (2) 确定包含所有可能的模型的假设空间，即学习模型和集合；

    (3) 确定模型选择的准则，即学习的策略；

    (4) 实现求解最优模型的算法，即学习的算法；

    (5) 通过学习方法选择最优模型；

    (6) 利用学习的最优模型对新数据进行预测或分析。

5. 统计学习的研究及重要性

    略

### 1.2 统计学习的分类

#### 1.2.1 基本分类

##### 1. 监督学习

监督学习(unsupervised learning)是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。监督学习的本质是学习输入到输出的映射的统计规律。

###### (1) 输入空间、特征空间和输出空间

在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间(input space)与输出空间(output space)。

每一个具体的输入是一个实例(instance)，通常由特征向量(feature vector)表示。这时，所有特征向量存在的空间称为特征空间(feature space)。特征空间的每一维对应于一个特征。

输入实例的特征向量记作：

$$x=(x^{(1)},x^{(2)},\cdots,x^{(i)},\cdots,x^{(n)})^T$$

$x^{(i)}$ 表示 $x$ 的第 $i$ 个特征。注意 $x^{(i)}$ 与 $x_i$ 不同，通常用 $x_i$ 表示多个输入变量中的第 $i$ 个变量，即：

$$x=(x^{(1)}_i,x^{(2)}_i,\cdots,x^{(i)}_i,\cdots,x^{(n)}_i)^T$$

监督学习从训练数据(training data)集合中学习模型，对测试数据(test data)进行预测。训练数据由输入(或特征向量)与输出对组成，训练集通常表示为：

$$T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}$$

测试数据也由输入与输出对组成。输入与输出对又称为样本(sample)或样本点。

输入变量 $X$ 和输出变量 $Y$ 有不同的类型，可以是连续的也可以是离散的。

输入变量与输出变量均为连续变量的预测问题称为回归问题；

输出变量为有限个离散变量的预测问题称为分类问题；

输入与输出变量均为变量序列的预测问题称为标注问题。

###### (2) 联合概率分布

监督学习假设输入与输出的随机变量 $X$ 和 $Y$ 遵循联合概率分布 $P(X,Y)$ 。 $P(X,Y)$ 表示分布函数，或分布密度函数。

学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的。训练数据与测试数据被看作是依联合概率分布 $P(X,Y)$ 独立同分布产生的。

统计学习假设数据存在一定的统计规律，$X$ 和 $Y$ 具有联合概率分布就是监督学习关于数据的基本假设。

###### (3) 假设空间

模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间(hypothesis space)。假设空间的确定意味着学习范围的确定。

监督学习的模型可以是概率模型或非概率模型，由条件概率分布 $P(Y{\vert}X)$ 或决策函数(decision function) $Y=f(X)$ 表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作 $P(y{\vert}x)$ 或 $y=f(x)$。

###### (4) 问题的形式化

监督学习分为学习和预测两个过程，由学习系统与预测系统完成。

首先给定一个训练数据集：

$$T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}$$

其中 $(x_i,y_i), i=1,2,\cdots,N$，称为样本或样本点。$x_i \in X \subseteq R^n$ 是输入的观测值，也称为输入或实例，$y_i \in Y$ 是输出的观测值，也称为输出。

在学习过程中，学习系统利用给定的训练数据集，通过学习(或训练)得到一个模型，表示为条件概率分布 $\hat{P}(Y{\vert}X)$ 或决策函数 $Y=\hat{f}(X)$。

在预测过程中，预测系统对于给定的测试样本集中的输入 $X_{N+1}$，由模型 $y_{N+1}={\arg}\ \underset{y}{\max}\ \hat{P}(y{\vert}x_{N+1})$ 或 $y_{N+1}=\hat{f}(x_{N+1})$ 给出相应的输出 $y_{N+1}$。

学习系统(也就是学习算法)试图通过训练数据集中的样本 $(x_i,y_i)$ 带来的信息学习模型。如果这个模型由很好的预测能力，训练样本输出 $y_i$ 和模型输出 $f(x_i)$ 之间的差就应该足够小。

学习系统经过不断地尝试，选取最好的模型，以便对训练数据集有足够好的预测，同时对未知的测试数据集的预测也有尽可能好的推广。

##### 2. 无监督学习

未完待续
